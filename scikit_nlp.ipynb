{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jerry\\AppData\\Local\\Temp\\ipykernel_12336\\1549811410.py:11: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def label_sentences(corpus, label_type):\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "import gensim\n",
    "from gensim.models import doc2vec\n",
    "import re\n",
    "import pandas as pd\n",
    "from numba import jit, cuda\n",
    "@jit\n",
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in tqdm(enumerate(corpus)):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(doc2vec.TaggedDocument(v.split(), [label]))\n",
    "    return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jerry\\AppData\\Local\\Temp\\ipykernel_12336\\3652498904.py:2: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def read_data():\n",
      "C:\\Users\\Jerry\\AppData\\Local\\Temp\\ipykernel_12336\\3652498904.py:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"read_data\" failed type inference due to: \u001b[1m\u001b[1mUnknown attribute 'read_csv' of type Module(<module 'pandas' from 'c:\\\\Users\\\\Jerry\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\pandas\\\\__init__.py'>)\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12336\\3652498904.py\", line 3:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of get attribute at C:\\Users\\Jerry\\AppData\\Local\\Temp\\ipykernel_12336\\3652498904.py (3)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12336\\3652498904.py\", line 3:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "c:\\Users\\Jerry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"read_data\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12336\\3652498904.py\", line 1:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\Users\\Jerry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12336\\3652498904.py\", line 1:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def read_data():\n",
    "    test_csv = pd.read_csv('datasets/cleaned_test_data.csv')\n",
    "    train_csv = pd.read_csv('datasets/cleaned_trained_data.csv')\n",
    "    test_csv = test_csv.drop(test_csv.index[0])\n",
    "    train_csv = train_csv.drop(train_csv.index[0])\n",
    "    return train_csv,test_csv\n",
    "train_data,test_data = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jerry\\AppData\\Local\\Temp\\ipykernel_27428\\1549811410.py:10: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"label_sentences\" failed type inference due to: \u001b[1mUntyped global name 'tqdm':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'type'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_27428\\1549811410.py\", line 18:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\Jerry\\AppData\\Local\\Temp\\ipykernel_27428\\1549811410.py:10: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"label_sentences\" failed type inference due to: \u001b[1mUntyped global name 'tqdm':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'type'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_27428\\1549811410.py\", line 18:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "c:\\Users\\Jerry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"label_sentences\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_27428\\1549811410.py\", line 10:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\Users\\Jerry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_27428\\1549811410.py\", line 10:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "0it [00:00, ?it/s]C:\\Users\\Jerry\\AppData\\Local\\Temp\\ipykernel_27428\\1549811410.py:10: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"label_sentences\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\Jerry\\AppData\\Local\\Temp\\ipykernel_27428\\1549811410.py (18)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_27428\\1549811410.py\", line 18:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "c:\\Users\\Jerry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"label_sentences\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_27428\\1549811410.py\", line 18:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\Users\\Jerry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_27428\\1549811410.py\", line 18:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "768325it [00:19, 40372.66it/s]\n",
      "32894it [00:00, 48039.24it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train_data = label_sentences(train_data['text'],'Train')\n",
    "x_test_data = label_sentences(test_data['text'],'Test')\n",
    "all_data = x_train_data + x_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801219/801219 [00:00<00:00, 1657312.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jerry\\Desktop\\AllApps\\Work\\Listster\\NLP\\scikit_nlp.ipynb Cell 4\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jerry/Desktop/AllApps/Work/Listster/NLP/scikit_nlp.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_dbow \u001b[39m=\u001b[39m Doc2Vec(dm\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, vector_size\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m, negative\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, min_count\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m0.065\u001b[39m, min_alpha\u001b[39m=\u001b[39m\u001b[39m0.065\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jerry/Desktop/AllApps/Work/Listster/NLP/scikit_nlp.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_dbow\u001b[39m.\u001b[39;49mbuild_vocab([x \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m tqdm(all_data)])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jerry/Desktop/AllApps/Work/Listster/NLP/scikit_nlp.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m@jit\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jerry/Desktop/AllApps/Work/Listster/NLP/scikit_nlp.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocessData\u001b[39m():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jerry/Desktop/AllApps/Work/Listster/NLP/scikit_nlp.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Jerry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\models\\doc2vec.py:888\u001b[0m, in \u001b[0;36mDoc2Vec.build_vocab\u001b[1;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorpus_count \u001b[39m=\u001b[39m corpus_count\n\u001b[0;32m    887\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorpus_total_words \u001b[39m=\u001b[39m total_words\n\u001b[1;32m--> 888\u001b[0m report_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_vocab(update\u001b[39m=\u001b[39mupdate, keep_raw_vocab\u001b[39m=\u001b[39mkeep_raw_vocab, trim_rule\u001b[39m=\u001b[39mtrim_rule, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    890\u001b[0m report_values[\u001b[39m'\u001b[39m\u001b[39mmemory\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimate_memory(vocab_size\u001b[39m=\u001b[39mreport_values[\u001b[39m'\u001b[39m\u001b[39mnum_retained_words\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    891\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_weights(update\u001b[39m=\u001b[39mupdate)\n",
      "File \u001b[1;32mc:\\Users\\Jerry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\models\\word2vec.py:776\u001b[0m, in \u001b[0;36mWord2Vec.prepare_vocab\u001b[1;34m(self, update, keep_raw_vocab, trim_rule, min_count, sample, dry_run)\u001b[0m\n\u001b[0;32m    773\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_binary_tree()\n\u001b[0;32m    774\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnegative:\n\u001b[0;32m    775\u001b[0m     \u001b[39m# build the table for drawing random words (for negative sampling)\u001b[39;00m\n\u001b[1;32m--> 776\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_cum_table()\n\u001b[0;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m report_values\n",
      "File \u001b[1;32mc:\\Users\\Jerry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\models\\word2vec.py:845\u001b[0m, in \u001b[0;36mWord2Vec.make_cum_table\u001b[1;34m(self, domain)\u001b[0m\n\u001b[0;32m    843\u001b[0m     count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwv\u001b[39m.\u001b[39mget_vecattr(word_index, \u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    844\u001b[0m     cumulative \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m count\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mfloat\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mns_exponent)\n\u001b[1;32m--> 845\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcum_table[word_index] \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(cumulative \u001b[39m/\u001b[39m train_words_pow \u001b[39m*\u001b[39m domain)\n\u001b[0;32m    846\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcum_table) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    847\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcum_table[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m domain\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])\n",
    "\n",
    "@jit\n",
    "def preprocessData():\n",
    "    for epoch in range(1):\n",
    "        print(epoch)\n",
    "        model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "        model_dbow.alpha -= 0.002\n",
    "        model_dbow.min_alpha = model_dbow.alpha\n",
    "preprocessData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/768325 [00:00<?, ?it/s]C:\\Users\\Jerry\\AppData\\Local\\Temp\\ipykernel_24028\\2779434855.py:14: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  vectors[i] = model.docvecs[prefix]\n",
      "100%|██████████| 768325/768325 [00:17<00:00, 44514.11it/s] \n",
      "100%|██████████| 32894/32894 [00:02<00:00, 16356.95it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in tqdm(range(0, corpus_size)):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors\n",
    "    \n",
    "train_vectors_dbow = get_vectors(model_dbow, len(x_train_data), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(x_test_data), 300, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {'Society & Culture' :1,'Science & Mathematics':2,'Health':3, 'Education & Reference':4,\n",
    "            'Computers & Internet' :5,'Sports' :6,'Business & Finance' :7,'Entertainment & Music' : 8,\n",
    "            'Family & Relationships':9, 'Politics & Government':10}\n",
    "train_data['class']=train_data['class'].map(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tags = [1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 9, 1, 5], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# @jit(target_backend='cuda')\n",
    "def buildModel():\n",
    "    logreg = LogisticRegression(n_jobs=1, C=1e5, max_iter=10000)\n",
    "    logreg = logreg.fit(train_vectors_dbow, train_data['class'])\n",
    "    y_pred = logreg.predict(test_vectors_dbow)\n",
    "    print('accuracy %s' % accuracy_score(y_pred, test_data['class']))\n",
    "# print(classification_report(test_data['class'], y_pred,target_names=my_tags))\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5, max_iter=10000)\n",
    "logreg = logreg.fit(train_vectors_dbow, train_data['class'])\n",
    "y_pred = logreg.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(y_pred, test_data['class']))\n",
    "# buildModel()\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jerry\\AppData\\Local\\Temp\\ipykernel_12336\\982528151.py:8: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def buildModel():\n",
      "C:\\Users\\Jerry\\AppData\\Local\\Temp\\ipykernel_12336\\982528151.py:7: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"buildModel\" failed type inference due to: \u001b[1mUntyped global name 'Pipeline':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'abc.ABCMeta'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12336\\982528151.py\", line 9:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "c:\\Users\\Jerry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"buildModel\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12336\\982528151.py\", line 7:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\Users\\Jerry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12336\\982528151.py\", line 7:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "@jit\n",
    "def buildModel():\n",
    "    logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "                ])\n",
    "    logreg.fit(train_data['text'], train_data['class'])\n",
    "    y_pred = logreg.predict(test_data['text'])\n",
    "    print('accuracy %s' % accuracy_score(y_pred, test_data['class']))\n",
    "    # print(classification_report(test_data['class'], y_pred,target_names=my_tags))\n",
    "buildModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jerry\\Desktop\\AllApps\\Work\\Listster\\NLP\\scikit_nlp.ipynb Cell 10\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jerry/Desktop/AllApps/Work/Listster/NLP/scikit_nlp.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m SGDClassifier\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jerry/Desktop/AllApps/Work/Listster/NLP/scikit_nlp.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sgd \u001b[39m=\u001b[39m Pipeline([(\u001b[39m'\u001b[39m\u001b[39mvect\u001b[39m\u001b[39m'\u001b[39m, CountVectorizer()),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jerry/Desktop/AllApps/Work/Listster/NLP/scikit_nlp.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                 (\u001b[39m'\u001b[39m\u001b[39mtfidf\u001b[39m\u001b[39m'\u001b[39m, TfidfTransformer()),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jerry/Desktop/AllApps/Work/Listster/NLP/scikit_nlp.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                 (\u001b[39m'\u001b[39m\u001b[39mclf\u001b[39m\u001b[39m'\u001b[39m, SGDClassifier(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhinge\u001b[39m\u001b[39m'\u001b[39m, penalty\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m'\u001b[39m,alpha\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, max_iter\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, tol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jerry/Desktop/AllApps/Work/Listster/NLP/scikit_nlp.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                ])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jerry/Desktop/AllApps/Work/Listster/NLP/scikit_nlp.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m sgd\u001b[39m.\u001b[39mfit(train_data[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m], train_data[\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jerry/Desktop/AllApps/Work/Listster/NLP/scikit_nlp.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m y_pred \u001b[39m=\u001b[39m sgd\u001b[39m.\u001b[39mpredict(test_data[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(train_data['text'], train_data['class'])\n",
    "\n",
    "y_pred = sgd.predict(test_data['text'])\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, test_data['class']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>makes friendship click ? spark keep going ? go...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zebras stripes ? purpose stripes ? serve Zebra...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>animals sense humour ? example , would dog dig...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>website HotorNot ? think website ? anyone met ...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>take photos e-commerce ? need take photos onli...</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32890</th>\n",
       "      <td>conservatives want us stay pay Iraq ? Cant see...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32891</th>\n",
       "      <td>else thinks ref ( uru ) reprimanded ! ? ! ? ! ...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32892</th>\n",
       "      <td>guys pleez ? anyone 4 13to15 want talk dont wa...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32893</th>\n",
       "      <td>Tell something life people n't know ....... ? ...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32894</th>\n",
       "      <td>sound low sound ? volume turned way video . ba...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32894 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text class  y_pred\n",
       "1      makes friendship click ? spark keep going ? go...     9       9\n",
       "2      Zebras stripes ? purpose stripes ? serve Zebra...     2       2\n",
       "3      animals sense humour ? example , would dog dig...     2       1\n",
       "4      website HotorNot ? think website ? anyone met ...     9       9\n",
       "5      take photos e-commerce ? need take photos onli...     7       5\n",
       "...                                                  ...   ...     ...\n",
       "32890  conservatives want us stay pay Iraq ? Cant see...    10      10\n",
       "32891  else thinks ref ( uru ) reprimanded ! ? ! ? ! ...     6       6\n",
       "32892  guys pleez ? anyone 4 13to15 want talk dont wa...     9       9\n",
       "32893  Tell something life people n't know ....... ? ...     8       1\n",
       "32894  sound low sound ? volume turned way video . ba...     5       5\n",
       "\n",
       "[32894 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['y_pred']=y_pred\n",
    "test_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
